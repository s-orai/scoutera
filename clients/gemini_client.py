from google import genai
from google.genai import types
import streamlit as st
from pydantic import BaseModel
from typing import List
import json
from contextlib import contextmanager
import time
import concurrent.futures

api_key = st.secrets["gemini"]["api_key"]
model = "gemini-3-pro-preview"
client = genai.Client(api_key=api_key)
n_trials = 3

# def __init__(self) -> None:
#   self.client = genai.Client(api_key=self.api_key)

class AiResult(BaseModel):
  """
  AIã®çµæœã‚’æ ¼ç´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
  """
  id: str
  required_condition: bool
  welcome_condition: bool
  evaluation_reason: str
  evaluation_result: str
  scout_message: str

class ResultsContainer(BaseModel):
  """çµæœå…¨ä½“ã‚’æ ¼ç´ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠ"""
  results: List[AiResult]

def request(pdf, job_pdf, config):
  try:
    job_pdf.append(pdf)
    response = client.models.generate_content(
        model=model,
        contents=job_pdf,
        config=config
    )
    result = ResultsContainer.model_validate_json(response.text)
    print(result)
    return result

  except Exception as e:
    print(f"âŒ Gemini APIã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    raise
  except json.JSONDecodeError as e:
    print(f"JSON Parse Error: {str(e)}")
    print("Invalid JSON content:", result)
    raise

def request_with_files_by_parallel(prompt, files, job_file, temperature):
  print("--- ä¸¦åˆ—å‡¦ç†é–‹å§‹ ---")
  start_time = time.time()

  ## response_schemaã®ä½œæˆ
  # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰JSONã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
  response_schema = ResultsContainer.model_json_schema()
  config = types.GenerateContentConfig(
    system_instruction=prompt,
    # JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’å¼·åˆ¶
    response_mime_type="application/json",
    response_schema = response_schema,
    temperature = temperature
  )

  with file_uploader(files, job_file) as (uploaded_files, uploaded_job_files):
    results = parallel_process_requests(uploaded_files, uploaded_job_files, config)

  end_time = time.time()
  print("--- ä¸¦åˆ—å‡¦ç†çµ‚äº† ---")
  print(f"åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
  print(f"results: {results}")
  return results

def parallel_process_requests(pdf_list, job_pdf_list, config):
    """
    PDFãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€å„PDFã«å¯¾ã—ã¦3å›ãšã¤APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€
    çµæœã‚’ä¸€ã¤ã®ãƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã¦è¿”ã—ã¾ã™ã€‚
    """
    # å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
    all_requests = []

    # PDFã”ã¨ã«3å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¼•æ•°ã‚’ä½œæˆ
    for pdf_path in pdf_list:
        for i in range(1, 4):  # 1å›ç›®ã€2å›ç›®ã€3å›ç›®
            all_requests.append((pdf_path, i))

    MAX_WORKERS = 10

    results = []

    # ThreadPoolExecutorã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # executor.submit() ã§ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã€Futureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        future_to_request = {
            executor.submit(request, pdf_path, job_pdf_list, config):
            (pdf_path, attempt_num)
            for pdf_path, attempt_num in all_requests
        }

        # concurrent.futures.as_completed() ã§å®Œäº†ã—ãŸé †ã«çµæœã‚’å–å¾—
        for future in concurrent.futures.as_completed(future_to_request):
            pdf_path, attempt_num = future_to_request[future]

            try:
                # future.result() ã§å®Ÿè¡Œçµæœã‚’å–å¾—
                result = future.result()
                results.append(result)
            except Exception as exc:
                print(f"PDF: {pdf_path}, è©¦è¡Œ: {attempt_num} ã®å®Ÿè¡Œä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {exc}")

    return results

@contextmanager
def file_uploader(files, job_file):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gemini APIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ 'with' ãƒ–ãƒ­ãƒƒã‚¯ã«æä¾›ã—ã¾ã™ã€‚
    ãƒ–ãƒ­ãƒƒã‚¯çµ‚äº†æ™‚ã«ã€æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšå¿…ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    """
    uploaded_file = None
    try:
      temp_uploaded_files = []
      for path, original_name in files:
        uploaded_file = client.files.upload(file=path)
        temp_uploaded_files.append(uploaded_file)
        print(f"  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {original_name}")

      temp_uploaded_job_files = []
      for path, original_name in job_file:
        uploaded_job_file = client.files.upload(file=path)
        temp_uploaded_job_files.append(uploaded_job_file)
        print(f"  æ±‚äººç¥¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {original_name}")

      yield (temp_uploaded_files, temp_uploaded_job_files)

    except Exception as e:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯ 'with' ãƒ–ãƒ­ãƒƒã‚¯å†…ã®å‡¦ç†ã§ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆ
        print(f"Error during file processing: {e}")
        raise # ä¾‹å¤–ã‚’å‘¼ã³å‡ºã—å…ƒã«å†ã‚¹ãƒ­ãƒ¼

    finally:
      ## 5. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ (Gemini Filesã‹ã‚‰)
      if uploaded_file:
        print(f"ğŸ—‘ï¸ Gemini Filesã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ« ({uploaded_file.name}) ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
        client.files.delete(name=uploaded_file.name)
        print("âœ… å‰Šé™¤å®Œäº†ã€‚")