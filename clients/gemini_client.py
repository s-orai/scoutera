from google.genai import types
import streamlit as st
from google import genai
from pydantic import BaseModel
from typing import List
import json
from contextlib import contextmanager
import time
import concurrent.futures

api_key = st.secrets["gemini"]["api_key"]
model = "gemini-3-pro-preview"

client = genai.Client(api_key=api_key)
n_trials = 3
# ãƒªãƒˆãƒ©ã‚¤å›æ•°ä¸Šé™
max_retries = 3
# ãƒªãƒˆãƒ©ã‚¤æ™‚ã®APIå•ã„åˆã‚ã›é–“éš”
backoff_seconds = 1.5

class AiResult(BaseModel):
  """
  AIã®çµæœã‚’æ ¼ç´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
  """
  id: str
  required_condition: bool
  welcome_condition: bool
  evaluation_reason: str
  evaluation_result: str
  scout_message: str

class ResultsContainer(BaseModel):
  """çµæœå…¨ä½“ã‚’æ ¼ç´ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠ"""
  results: List[AiResult]

class CreatePromptModel(BaseModel):
  common_skill_of_A: str
  difference_of_ab_and_c: str
  difference_of_a_and_b: str
  required_condition: str
  welcome_condition: str

class ScoutMaterialModel(BaseModel):
  persona: str
  category: str
  industry: str
  keyword: str
  income: str
  desired_income: str
  scout_title: str
  scout_body: str

def request_for_create_prompt(prompt, files, job_file, temperature):
  print("--- å‡¦ç†é–‹å§‹ ---")
  start_time = time.time()

  ## response_schemaã®ä½œæˆ
  # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰JSONã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
  response_schema = CreatePromptModel.model_json_schema()
  config = types.GenerateContentConfig(
    system_instruction=prompt,
    # JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’å¼·åˆ¶
    response_mime_type="application/json",
    response_schema = response_schema,
    temperature = temperature
  )

  with file_uploader(files, job_file) as (uploaded_files, uploaded_job_files):
    response = request(uploaded_files, uploaded_job_files, config)
    result = CreatePromptModel.model_validate_json(response.text)
    print(result)

  end_time = time.time()
  print("--- ä¸¦åˆ—å‡¦ç†çµ‚äº† ---")
  print(f"åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
  print(f"result: {result}")
  return result

def request(pdf, job_pdfs, config):
  for attempt in range(1, max_retries + 1):
    try:
      # APIå‘¼ã³å‡ºã—
      contents = [pdf] + list(job_pdfs)
      response = client.models.generate_content(
          model=model,
          contents=contents,
          config=config
      )
      return response

    except json.JSONDecodeError as e:
      # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ãƒªãƒˆãƒ©ã‚¤ã—ã¦ã‚‚è§£æ±ºã—ãªã„ãŸã‚ã€å³åº§ã«ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
      print(f"JSON Parse Error: {str(e)}")
      print("Invalid JSON content:", response.text if 'response' in locals() else '')
      raise

    except Exception as e:
      # æœ€å¾Œã®è©¦è¡Œã®å ´åˆã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
      if attempt == max_retries:
        print(f"âŒ Gemini APIã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (attempt {attempt}/{max_retries}): {e}")
        raise

      print(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼ (attempt {attempt}/{max_retries}): {e} - {backoff_seconds}ç§’å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
      time.sleep(backoff_seconds)
      # ãƒ«ãƒ¼ãƒ—ãŒç¶™ç¶šã•ã‚Œã€æ¬¡ã®è©¦è¡ŒãŒå®Ÿè¡Œã•ã‚Œã‚‹

def request_with_files_by_parallel(prompt, files, job_file, temperature):
  print("--- ä¸¦åˆ—å‡¦ç†é–‹å§‹ ---")
  start_time = time.time()

  ## response_schemaã®ä½œæˆ
  # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰JSONã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
  response_schema = ResultsContainer.model_json_schema()
  config = types.GenerateContentConfig(
    system_instruction=prompt,
    # JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’å¼·åˆ¶
    response_mime_type="application/json",
    response_schema = response_schema,
    temperature = temperature
  )

  with file_uploader(files, job_file) as (uploaded_files, uploaded_job_files):
    results = parallel_process_requests(uploaded_files, uploaded_job_files, config)

  end_time = time.time()
  print("--- ä¸¦åˆ—å‡¦ç†çµ‚äº† ---")
  print(f"åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
  print(f"results: {results}")
  return results

def parallel_process_requests(pdf_list, job_pdf_list, config):
    """
    PDFãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€å„PDFã«å¯¾ã—ã¦3å›ãšã¤APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€
    çµæœã‚’ä¸€ã¤ã®ãƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã¦è¿”ã—ã¾ã™ã€‚
    """
    all_requests = [
        (pdf_path, attempt_num)
        for pdf_path in pdf_list
        for attempt_num in range(1, 4)
    ]

    MAX_WORKERS = 10
    results = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_request = {
            executor.submit(request, pdf_path, job_pdf_list, config):
            (pdf_path, attempt_num)
            for pdf_path, attempt_num in all_requests
        }

        for future in concurrent.futures.as_completed(future_to_request):
            pdf_path, attempt_num = future_to_request[future]
            try:
                response = future.result()
                result = ResultsContainer.model_validate_json(response.text)
                print(result)
                results.append(result)
            except Exception as exc:
                print(f"PDF: {pdf_path}, è©¦è¡Œ: {attempt_num} ã®å®Ÿè¡Œä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {exc}")

    return results

def request_with_files_for_scout_material(prompt, files, temperature):
  print("--- å‡¦ç†é–‹å§‹ ---")
  start_time = time.time()

  ## response_schemaã®ä½œæˆ
  # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰JSONã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
  response_schema = ScoutMaterialModel.model_json_schema()
  config = types.GenerateContentConfig(
    system_instruction=prompt,
    # JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’å¼·åˆ¶
    response_mime_type="application/json",
    response_schema = response_schema,
    temperature = temperature
  )

  with _file_uploader(files) as uploaded_files:
    response = _request(uploaded_files, config)

  end_time = time.time()
  print(f"åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™ï¼ˆlogicå´ã§tuple/listã¨å‹˜é•ã„ã—ãªã„ã‚ˆã†ã«ï¼‰
  result = ScoutMaterialModel.model_validate_json(response.text)
  print(f"result: {result}")
  return result

# ----------------------------
# ã“ã“ã‹ã‚‰ã¯jdç”¨
# ï¼Šå¾Œã§çµ±åˆã™ã‚‹ã“ã¨ï¼ï¼
# ----------------------------
class OfferingContentModel(BaseModel):
  background: str
  job_category: str
  required_requirement: str
  welcome_requirement: str
  character_statue: str

class BussinessDescriptionModel(BaseModel):
  company_name: str
  business_service_name: str
  company_philosophy: str
  business_introduction: str
  business_detail: str

def request_business_description(prompt, temperature):
  print("--- å‡¦ç†é–‹å§‹ ---")
  start_time = time.time()

  ## response_schemaã®ä½œæˆ
  # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰JSONã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
  response_schema = BussinessDescriptionModel.model_json_schema()
  config = types.GenerateContentConfig(
    # JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’å¼·åˆ¶
    response_mime_type="application/json",
    response_schema = response_schema,
    temperature = temperature
  )

  response = _request_only_config(config, prompt)
  result = BussinessDescriptionModel.model_validate_json(response.text)

  end_time = time.time()
  print(f"åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
  return result

def request_with_files_for_jd(prompt, files, temperature):
  print("--- å‡¦ç†é–‹å§‹ ---")
  start_time = time.time()

  ## response_schemaã®ä½œæˆ
  # Pydanticãƒ¢ãƒ‡ãƒ«ã‹ã‚‰JSONã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—
  response_schema = OfferingContentModel.model_json_schema()
  config = types.GenerateContentConfig(
    system_instruction=prompt,
    # JSONå½¢å¼ã§ã®å‡ºåŠ›ã‚’å¼·åˆ¶
    response_mime_type="application/json",
    response_schema = response_schema,
    temperature = temperature
  )

  with _file_uploader(files) as uploaded_files:
    response = _request(uploaded_files, config)

  end_time = time.time()
  print(f"åˆè¨ˆå®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™ï¼ˆlogicå´ã§tuple/listã¨å‹˜é•ã„ã—ãªã„ã‚ˆã†ã«ï¼‰
  result = OfferingContentModel.model_validate_json(response.text)
  print(f"result: {result}")
  return result

def _request_only_config(config, prompt):
  for attempt in range(1, max_retries + 1):
    try:
      # APIå‘¼ã³å‡ºã—
      response = client.models.generate_content(
          model=model,
          config=config,
          contents=[prompt]
      )
      return response

    except json.JSONDecodeError as e:
      # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ãƒªãƒˆãƒ©ã‚¤ã—ã¦ã‚‚è§£æ±ºã—ãªã„ãŸã‚ã€å³åº§ã«ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
      print(f"JSON Parse Error: {str(e)}")
      print("Invalid JSON content:", response.text if 'response' in locals() else '')
      raise

    except Exception as e:
      # æœ€å¾Œã®è©¦è¡Œã®å ´åˆã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
      if attempt == max_retries:
        print(f"âŒ Gemini APIã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (attempt {attempt}/{max_retries}): {e}")
        raise

      print(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼ (attempt {attempt}/{max_retries}): {e} - {backoff_seconds}ç§’å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
      time.sleep(backoff_seconds)
      # ãƒ«ãƒ¼ãƒ—ãŒç¶™ç¶šã•ã‚Œã€æ¬¡ã®è©¦è¡ŒãŒå®Ÿè¡Œã•ã‚Œã‚‹

def _request(pdfs, config):
  for attempt in range(1, max_retries + 1):
    try:
      # APIå‘¼ã³å‡ºã—
      contents = pdfs
      response = client.models.generate_content(
          model=model,
          contents=contents,
          config=config
      )
      return response

    except json.JSONDecodeError as e:
      # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ãƒªãƒˆãƒ©ã‚¤ã—ã¦ã‚‚è§£æ±ºã—ãªã„ãŸã‚ã€å³åº§ã«ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
      print(f"JSON Parse Error: {str(e)}")
      print("Invalid JSON content:", response.text if 'response' in locals() else '')
      raise

    except Exception as e:
      # æœ€å¾Œã®è©¦è¡Œã®å ´åˆã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿ
      if attempt == max_retries:
        print(f"âŒ Gemini APIã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (attempt {attempt}/{max_retries}): {e}")
        raise

      print(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼ (attempt {attempt}/{max_retries}): {e} - {backoff_seconds}ç§’å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
      time.sleep(backoff_seconds)
      # ãƒ«ãƒ¼ãƒ—ãŒç¶™ç¶šã•ã‚Œã€æ¬¡ã®è©¦è¡ŒãŒå®Ÿè¡Œã•ã‚Œã‚‹

# ----------------------------
# å…±é€šé–¢æ•°
# ----------------------------
@contextmanager
def file_uploader(files, job_file, is_round: bool = False):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gemini APIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ 'with' ãƒ–ãƒ­ãƒƒã‚¯ã«æä¾›ã—ã¾ã™ã€‚
    ãƒ–ãƒ­ãƒƒã‚¯çµ‚äº†æ™‚ã«ã€æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšå¿…ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    """
    uploaded_files = []
    uploaded_job_files = []
    try:
      for path, original_name in files:
        uploaded = client.files.upload(file=path)
        uploaded_files.append(uploaded)
        print(f"  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {original_name}")

      for path, original_name in job_file:
        uploaded = client.files.upload(file=path)
        uploaded_job_files.append(uploaded)
        print(f"  æ±‚äººç¥¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {original_name}")

      if not is_round:
        yield (uploaded_files, uploaded_job_files)
      else:
        uploaded_files.extend(uploaded_job_files)
        yield uploaded_files

    except Exception as e:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯ 'with' ãƒ–ãƒ­ãƒƒã‚¯å†…ã®å‡¦ç†ã§ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆ
        print(f"Error during file processing: {e}")
        raise # ä¾‹å¤–ã‚’å‘¼ã³å‡ºã—å…ƒã«å†ã‚¹ãƒ­ãƒ¼

    finally:
      ## 5. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ (Gemini Filesã‹ã‚‰)
      for uploaded in uploaded_files + uploaded_job_files:
        try:
          print(f"ğŸ—‘ï¸ Gemini Filesã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ« ({uploaded.name}) ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
          client.files.delete(name=uploaded.name)
          print("âœ… å‰Šé™¤å®Œäº†ã€‚")
        except Exception as delete_error:
          print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {delete_error}")

@contextmanager
def _file_uploader(files):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gemini APIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ 'with' ãƒ–ãƒ­ãƒƒã‚¯ã«æä¾›ã—ã¾ã™ã€‚
    ãƒ–ãƒ­ãƒƒã‚¯çµ‚äº†æ™‚ã«ã€æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšå¿…ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    """
    uploaded_files = []
    try:
      for path, original_name in files:
        uploaded = client.files.upload(file=path)
        uploaded_files.append(uploaded)
        print(f"  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {original_name}")

      # 1ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å˜ä½“ã§ã€è¤‡æ•°ã®å ´åˆã¯ãƒªã‚¹ãƒˆã§æ¸¡ã™
      if len(uploaded_files) == 1:
        yield uploaded_files[0]
      else:
        yield uploaded_files

    except Exception as e:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯ 'with' ãƒ–ãƒ­ãƒƒã‚¯å†…ã®å‡¦ç†ã§ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆ
        print(f"Error during file processing: {e}")
        raise # ä¾‹å¤–ã‚’å‘¼ã³å‡ºã—å…ƒã«å†ã‚¹ãƒ­ãƒ¼

    finally:
      ## 5. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ (Gemini Filesã‹ã‚‰)
      for uploaded in uploaded_files:
        try:
          print(f"ğŸ—‘ï¸ Gemini Filesã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ« ({uploaded.name}) ã‚’å‰Šé™¤ã—ã¾ã™ã€‚")
          client.files.delete(name=uploaded.name)
          print("âœ… å‰Šé™¤å®Œäº†ã€‚")
        except Exception as delete_error:
          print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {delete_error}")